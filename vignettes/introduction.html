<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Will Lowe" />

<meta name="date" content="2015-05-25" />

<title>Counting and viewing words and categories</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link href="data:text/css,body%20%7B%0A%20%20background%2Dcolor%3A%20%23fff%3B%0A%20%20margin%3A%201em%20auto%3B%0A%20%20max%2Dwidth%3A%20700px%3B%0A%20%20overflow%3A%20visible%3B%0A%20%20padding%2Dleft%3A%202em%3B%0A%20%20padding%2Dright%3A%202em%3B%0A%20%20font%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0A%20%20font%2Dsize%3A%2014px%3B%0A%20%20line%2Dheight%3A%201%2E35%3B%0A%7D%0A%0A%23header%20%7B%0A%20%20text%2Dalign%3A%20center%3B%0A%7D%0A%0A%23TOC%20%7B%0A%20%20clear%3A%20both%3B%0A%20%20margin%3A%200%200%2010px%2010px%3B%0A%20%20padding%3A%204px%3B%0A%20%20width%3A%20400px%3B%0A%20%20border%3A%201px%20solid%20%23CCCCCC%3B%0A%20%20border%2Dradius%3A%205px%3B%0A%0A%20%20background%2Dcolor%3A%20%23f6f6f6%3B%0A%20%20font%2Dsize%3A%2013px%3B%0A%20%20line%2Dheight%3A%201%2E3%3B%0A%7D%0A%20%20%23TOC%20%2Etoctitle%20%7B%0A%20%20%20%20font%2Dweight%3A%20bold%3B%0A%20%20%20%20font%2Dsize%3A%2015px%3B%0A%20%20%20%20margin%2Dleft%3A%205px%3B%0A%20%20%7D%0A%0A%20%20%23TOC%20ul%20%7B%0A%20%20%20%20padding%2Dleft%3A%2040px%3B%0A%20%20%20%20margin%2Dleft%3A%20%2D1%2E5em%3B%0A%20%20%20%20margin%2Dtop%3A%205px%3B%0A%20%20%20%20margin%2Dbottom%3A%205px%3B%0A%20%20%7D%0A%20%20%23TOC%20ul%20ul%20%7B%0A%20%20%20%20margin%2Dleft%3A%20%2D2em%3B%0A%20%20%7D%0A%20%20%23TOC%20li%20%7B%0A%20%20%20%20line%2Dheight%3A%2016px%3B%0A%20%20%7D%0A%0Atable%20%7B%0A%20%20margin%3A%201em%20auto%3B%0A%20%20border%2Dwidth%3A%201px%3B%0A%20%20border%2Dcolor%3A%20%23DDDDDD%3B%0A%20%20border%2Dstyle%3A%20outset%3B%0A%20%20border%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0A%20%20border%2Dwidth%3A%202px%3B%0A%20%20padding%3A%205px%3B%0A%20%20border%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0A%20%20border%2Dwidth%3A%201px%3B%0A%20%20border%2Dstyle%3A%20inset%3B%0A%20%20line%2Dheight%3A%2018px%3B%0A%20%20padding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0A%20%20border%2Dleft%2Dstyle%3A%20none%3B%0A%20%20border%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0A%0Ap%20%7B%0A%20%20margin%3A%200%2E5em%200%3B%0A%7D%0A%0Ablockquote%20%7B%0A%20%20background%2Dcolor%3A%20%23f6f6f6%3B%0A%20%20padding%3A%200%2E25em%200%2E75em%3B%0A%7D%0A%0Ahr%20%7B%0A%20%20border%2Dstyle%3A%20solid%3B%0A%20%20border%3A%20none%3B%0A%20%20border%2Dtop%3A%201px%20solid%20%23777%3B%0A%20%20margin%3A%2028px%200%3B%0A%7D%0A%0Adl%20%7B%0A%20%20margin%2Dleft%3A%200%3B%0A%7D%0A%20%20dl%20dd%20%7B%0A%20%20%20%20margin%2Dbottom%3A%2013px%3B%0A%20%20%20%20margin%2Dleft%3A%2013px%3B%0A%20%20%7D%0A%20%20dl%20dt%20%7B%0A%20%20%20%20font%2Dweight%3A%20bold%3B%0A%20%20%7D%0A%0Aul%20%7B%0A%20%20margin%2Dtop%3A%200%3B%0A%7D%0A%20%20ul%20li%20%7B%0A%20%20%20%20list%2Dstyle%3A%20circle%20outside%3B%0A%20%20%7D%0A%20%20ul%20ul%20%7B%0A%20%20%20%20margin%2Dbottom%3A%200%3B%0A%20%20%7D%0A%0Apre%2C%20code%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20color%3A%20%23333%3B%0A%7D%0Apre%20%7B%0A%20%20white%2Dspace%3A%20pre%2Dwrap%3B%20%20%20%20%2F%2A%20Wrap%20long%20lines%20%2A%2F%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20margin%3A%205px%200px%2010px%200px%3B%0A%20%20padding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0A%0Acode%20%7B%0A%20%20font%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0A%20%20font%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0A%20%20padding%3A%202px%200px%3B%0A%7D%0A%0Adiv%2Efigure%20%7B%0A%20%20text%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0A%20%20background%2Dcolor%3A%20%23FFFFFF%3B%0A%20%20padding%3A%202px%3B%0A%20%20border%3A%201px%20solid%20%23DDDDDD%3B%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20border%3A%201px%20solid%20%23CCCCCC%3B%0A%20%20margin%3A%200%205px%3B%0A%7D%0A%0Ah1%20%7B%0A%20%20margin%2Dtop%3A%200%3B%0A%20%20font%2Dsize%3A%2035px%3B%0A%20%20line%2Dheight%3A%2040px%3B%0A%7D%0A%0Ah2%20%7B%0A%20%20border%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0A%20%20padding%2Dtop%3A%2010px%3B%0A%20%20padding%2Dbottom%3A%202px%3B%0A%20%20font%2Dsize%3A%20145%25%3B%0A%7D%0A%0Ah3%20%7B%0A%20%20border%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0A%20%20padding%2Dtop%3A%2010px%3B%0A%20%20font%2Dsize%3A%20120%25%3B%0A%7D%0A%0Ah4%20%7B%0A%20%20border%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0A%20%20margin%2Dleft%3A%208px%3B%0A%20%20font%2Dsize%3A%20105%25%3B%0A%7D%0A%0Ah5%2C%20h6%20%7B%0A%20%20border%2Dbottom%3A%201px%20solid%20%23ccc%3B%0A%20%20font%2Dsize%3A%20105%25%3B%0A%7D%0A%0Aa%20%7B%0A%20%20color%3A%20%230033dd%3B%0A%20%20text%2Ddecoration%3A%20none%3B%0A%7D%0A%20%20a%3Ahover%20%7B%0A%20%20%20%20color%3A%20%236666ff%3B%20%7D%0A%20%20a%3Avisited%20%7B%0A%20%20%20%20color%3A%20%23800080%3B%20%7D%0A%20%20a%3Avisited%3Ahover%20%7B%0A%20%20%20%20color%3A%20%23BB00BB%3B%20%7D%0A%20%20a%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0A%20%20%20%20text%2Ddecoration%3A%20underline%3B%20%7D%0A%20%20a%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0A%20%20%20%20text%2Ddecoration%3A%20underline%3B%20%7D%0A%0A%2F%2A%20Class%20described%20in%20https%3A%2F%2Fbenjeffrey%2Ecom%2Fposts%2Fpandoc%2Dsyntax%2Dhighlighting%2Dcss%0A%20%20%20Colours%20from%20https%3A%2F%2Fgist%2Egithub%2Ecom%2Frobsimmons%2F1172277%20%2A%2F%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20Keyword%20%2A%2F%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%2F%2A%20DataType%20%2A%2F%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%2F%2A%20DecVal%20%28decimal%20values%29%20%2A%2F%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20BaseN%20%2A%2F%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20Float%20%2A%2F%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20Char%20%2A%2F%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20String%20%2A%2F%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%2F%2A%20Comment%20%2A%2F%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%2F%2A%20OtherToken%20%2A%2F%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20AlertToken%20%2A%2F%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20Function%20calls%20%2A%2F%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%2F%2A%20ErrorTok%20%2A%2F%0A%0A" rel="stylesheet" type="text/css" />

</head>

<body>



<div id="header">
<h1 class="title">Counting and viewing words and categories</h1>
<h4 class="author"><em>Will Lowe</em></h4>
<h4 class="date"><em>2015-05-25</em></h4>
</div>


<p>This package consists of R functions to drive the java code in jca tools. You can find that <a href="https://github.com/conjugateprior/jca">here</a>. It’s a light wrapper and not thoroughly tested, but it might do what you want. The first task, which is probably the hardest, is to get Java and R working together. That’s covered in the other vignette.</p>
<p>In this one we exercise the package on a small content analysis example.</p>
<div id="describing-documents" class="section level2">
<h2>Describing documents</h2>
<p>Let’s start by describing some documents. We’ll use a replication data set from Bara et al.’s analysis of a parliamentary debate on relaxing the abortion laws that took place in Britain in the 60s. The data has been scraped from Hansard and each speaker’s contributions to the debate concatenated. Consequently each document is named after the speaker whose contributions it contains.</p>
<p>First we load the package and find the data folder</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rjca)
deb &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;debate-by-speaker&quot;</span>, <span class="dt">package=</span><span class="st">&quot;rjca&quot;</span>)
<span class="kw">dir</span>(deb) ## list the files </code></pre>
<pre><code>##  [1] &quot;abs-Mr William Deedes.txt&quot;       &quot;abs-Sir John Hobson.txt&quot;        
##  [3] &quot;no-Mr Kevin McNamara.txt&quot;        &quot;no-Mr Norman St John-Stevas.txt&quot;
##  [5] &quot;no-Mr Peter Mahon.txt&quot;           &quot;no-Mr William Wells.txt&quot;        
##  [7] &quot;no-Mrs Jill Knight.txt&quot;          &quot;yes-Dr David Owen.txt&quot;          
##  [9] &quot;yes-Dr John Dunwoody.txt&quot;        &quot;yes-Dr Michael Winstanley.txt&quot;  
## [11] &quot;yes-Hon. Sam Silkin.txt&quot;         &quot;yes-Miss Joan Vickers.txt&quot;      
## [13] &quot;yes-Mr Alex Lyon.txt&quot;            &quot;yes-Mr Angus Maude.txt&quot;         
## [15] &quot;yes-Mr Charles Pannell.txt&quot;      &quot;yes-Mr David Steel.txt&quot;         
## [17] &quot;yes-Mr Edward Lyons.txt&quot;         &quot;yes-Mr Leo Abse.txt&quot;            
## [19] &quot;yes-Mr Roy Jenkins.txt&quot;          &quot;yes-Mrs Gwyneth Dunwoody.txt&quot;   
## [21] &quot;yes-Mrs Renee Short.txt&quot;         &quot;yes-Sir Henry Legge-Bourke.txt&quot;</code></pre>
<p>In case you are wondering, the prefix on the speaker names indicates whether they abstained, voted yes or voted no after the debate.</p>
<p>Let’s compute some summary statistics</p>
<pre class="sourceCode r"><code class="sourceCode r">desc &lt;-<span class="st"> </span><span class="kw">jca_desc</span>(deb)</code></pre>
<pre><code>## File is /var/folders/gl/ds8cxcyj07x0f553zt__04mm0000gn/T//RtmpLGRRKB/jca_descc6d264aa486d.csv</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(desc) ## top of the file</code></pre>
<pre><code>##                                 TokenCount TypeCount HapaxCount
## abs-Mr William Deedes.txt             1478       502        307
## abs-Sir John Hobson.txt               2808       677        358
## no-Mr Kevin McNamara.txt              3009       854        509
## no-Mr Norman St John-Stevas.txt       2245       673        410
## no-Mr Peter Mahon.txt                   70        53         42
## no-Mr William Wells.txt               2606       718        411
##                                 PropVocabUsed TypeTokenRatio SentenceCount
## abs-Mr William Deedes.txt               0.140          0.340            84
## abs-Sir John Hobson.txt                 0.189          0.241           132
## no-Mr Kevin McNamara.txt                0.238          0.284           141
## no-Mr Norman St John-Stevas.txt         0.188          0.300           127
## no-Mr Peter Mahon.txt                   0.015          0.757             6
## no-Mr William Wells.txt                 0.200          0.276           147</code></pre>
<p>This functions computes the number of words, number of word types, number of words that occurred exactly once, the proportion of all words used that were deployed in this document, the ratio of word types to word tokens, and the number of sentences, for each of the documents.</p>
<p>All the <code>jca_</code> functions run their java in the background and drop the results into a file or folder. This function returned a data frame but also reported the temporary location where the output landed so you can look at it more closely if you want.</p>
<p>Also common to all the functions is the possibility to add information about the documents, e.g. their file encoding and their locale. Here we’ve taken the system default locale. If we wanted to specify that the document were encoded in KOI8-R (a Russian encoding) then we would instead use</p>
<pre class="sourceCode r"><code class="sourceCode r">desc &lt;-<span class="st"> </span><span class="kw">jca_desc</span>(deb, <span class="dt">encoding=</span><span class="st">'KOI8-R'</span>)</code></pre>
<p>As it happens this would not affect much since the text is almost completely ASCII characters. For other documents, specifying the encoding will be vital for recognizing the words in the document.</p>
<p>It is worth noting that, whatever encoding the documents arrive in, the output of these functions will be UTF-8. This is taken into account by the package, but you may need to know that if you read in the file and folder output with other programs on a system that does not have a system UTF-8 encoding (due to mistaken setup, deliberate perversity, or MS Windows - but I repeat myself).</p>
</div>
<div id="counting-words" class="section level2">
<h2>Counting words</h2>
<p>To get a word frequency matrix for these documents</p>
<pre class="sourceCode r"><code class="sourceCode r">wfmat &lt;-<span class="st"> </span><span class="kw">jca_word</span>(deb)</code></pre>
<pre><code>## Folder is /var/folders/gl/ds8cxcyj07x0f553zt__04mm0000gn/T//RtmpLGRRKB/jca_wordc6d22efbca1a</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(wfmat)</code></pre>
<pre><code>## [1]   22 3588</code></pre>
<p>The output is a sparse matrix so we aren’t storing the thousands of zero counts that inevitably occur. If you want to work with it further, remember to load the Matrix package.</p>
<p>Sometimes we’d prefer to do some filtering before constructing the matrix. This function allows you to remove numbers, currency amounts, stop words (if you provide a filename with the words in it), and to reduce to word stems in several languages using the snowball stemmer.</p>
<p>For example, if we wanted to remove numbers and currency and apply a stemmer</p>
<pre class="sourceCode r"><code class="sourceCode r">wfmat2 &lt;-<span class="st"> </span><span class="kw">jca_word</span>(deb, <span class="dt">no.currency=</span><span class="ot">TRUE</span>, <span class="dt">no.numbers=</span><span class="ot">TRUE</span>, <span class="dt">stemmer=</span><span class="st">'english'</span>)</code></pre>
<pre><code>## Folder is /var/folders/gl/ds8cxcyj07x0f553zt__04mm0000gn/T//RtmpLGRRKB/jca_wordc6d25ebd4255</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(wfmat2) ## now rather smaller</code></pre>
<pre><code>## [1]   22 2452</code></pre>
</div>
<div id="counting-categories" class="section level2">
<h2>Counting categories</h2>
<p>Counting words is fun but counting categories are funner. Using a content analysis dictionary also allows us to define and count phrases.</p>
<p>We’ll use the dictionary for the Bara et al. study. This lives next to the documents in the package</p>
<pre class="sourceCode r"><code class="sourceCode r">dict &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;bara-et-al.ykd&quot;</span>, <span class="dt">package=</span><span class="st">&quot;rjca&quot;</span>)</code></pre>
<p>The file is in Yoshikoder format, an XML format that represents hierarchically structured content analysis dictionaries and is designed to work in the Yoshikoder software. However, the <code>jca_cat</code> and <code>jca_conc</code> functions accept dictionary files in the following formats, recognizing each from the suffix of the file</p>
<ul>
<li>Yoshikoder (suffix <code>.ykd</code>)</li>
<li>VBPro (suffix <code>.vbpro</code>)</li>
<li>Lexicoder (suffix <code>.lcd</code>)</li>
<li>LIWC (suffix: <code>.dic</code>)</li>
<li>Wordstat (suffix <code>.CAT</code> <em>experimental</em>)</li>
</ul>
<p>The VBPro format is particularly convenient for throwing together a dictionary by hand in a hurry. Such dictionaries look like</p>
<pre><code>&gt;&gt;Advocacy&lt;&lt;
object*
override
&gt;&gt;Religion&lt;&lt;
relig*
catholic church</code></pre>
<p>where the category names are anything between <code>&gt;&gt;</code> and <code>&lt;&lt;</code> and the words underneath are word or phrase patterns to match, one per line. You can write one of these in any text editor and hand it to the function as a dictionary (to be quite sure you’re matching what you think you’re matching, save the dictionary file as ‘UTF-8’).</p>
<p>This format is reasonably flexible; you can use wildcards and multiword patterns, but the dictionary has no nested categories so you’ll have to fake those with your category naming convention.</p>
<p>OK, back to the content analysis. Let’s run this dictionary over the debate documents</p>
<pre class="sourceCode r"><code class="sourceCode r">debca &lt;-<span class="st"> </span><span class="kw">jca_cat</span>(dict, deb)</code></pre>
<pre><code>## Folder is /var/folders/gl/ds8cxcyj07x0f553zt__04mm0000gn/T//RtmpLGRRKB/jca_catc6d29573a51</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(debca) ## a bit messy</code></pre>
<pre><code>##                                 debate debate_advocacy debate_legal
## abs-Mr William Deedes.txt          201              36           11
## abs-Sir John Hobson.txt            348              36           22
## no-Mr Kevin McNamara.txt           406              68           38
## no-Mr Norman St John-Stevas.txt    318              63           26
## no-Mr Peter Mahon.txt               13               1            0
## no-Mr William Wells.txt            354              61           24
##                                 debate_medical debate_moral
## abs-Mr William Deedes.txt                   28           14
## abs-Sir John Hobson.txt                     65            9
## no-Mr Kevin McNamara.txt                    96            8
## no-Mr Norman St John-Stevas.txt             50           32
## no-Mr Peter Mahon.txt                        1            1
## no-Mr William Wells.txt                     73           21
##                                 debate_procedural debate_social WordCount
## abs-Mr William Deedes.txt                      87            25      1478
## abs-Sir John Hobson.txt                       144            72      2808
## no-Mr Kevin McNamara.txt                      125            71      3009
## no-Mr Norman St John-Stevas.txt               112            35      2245
## no-Mr Peter Mahon.txt                           8             2        70
## no-Mr William Wells.txt                       128            47      2606</code></pre>
<p>The root node of the dictionary gives it its name ‘debate’. Hence the first column ‘debate’ contains the count of words or phrases (there are only words in this dictionary) that match any pattern in any category. The next column ‘debate_advocacy’ is named to indicate that ‘advocacy’ is a subcategory of ‘debate’. Note that the counts in all the subcategories of ‘debate’ will add up to the count in the ‘debate’ category, and so on nestedly downwards if there were more structure in this dictionary.</p>
<p>The document word counts are included so that it is possible to say that e.g. McNamara deploys words in the medical category at a rate of about 32 words per thousand (because 96/3009 * 1000 = 31.9) in comparison to Deedes who use them at about 19 per thousand.</p>
<p>By dividing the subcategory counts by the ‘debate’ column we get the proportions of words each deploys on the medical topic, disregarding all the words that are not categorised by the dictionary.</p>
<p>For more complex dictionaries there are some subtleties to using this flattened output. For most purposes you can just use the convenience function <code>dict_slice</code>.</p>
<p>For example, here we’ll slice the dictionary at level 1, that is: the top level categories, one level down from the root (any lower level category counts will be nested) in these</p>
<pre class="sourceCode r"><code class="sourceCode r">debca1 &lt;-<span class="st"> </span><span class="kw">dict_slice</span>(debca, <span class="dt">level=</span><span class="dv">1</span>)</code></pre>
<p>The top of the output now looks more friendly</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">advocacy</th>
<th align="right">legal</th>
<th align="right">medical</th>
<th align="right">moral</th>
<th align="right">procedural</th>
<th align="right">social</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">abs-Mr William Deedes.txt</td>
<td align="right">36</td>
<td align="right">11</td>
<td align="right">28</td>
<td align="right">14</td>
<td align="right">87</td>
<td align="right">25</td>
</tr>
<tr class="even">
<td align="left">abs-Sir John Hobson.txt</td>
<td align="right">36</td>
<td align="right">22</td>
<td align="right">65</td>
<td align="right">9</td>
<td align="right">144</td>
<td align="right">72</td>
</tr>
<tr class="odd">
<td align="left">no-Mr Kevin McNamara.txt</td>
<td align="right">68</td>
<td align="right">38</td>
<td align="right">96</td>
<td align="right">8</td>
<td align="right">125</td>
<td align="right">71</td>
</tr>
<tr class="even">
<td align="left">no-Mr Norman St John-Stevas.txt</td>
<td align="right">63</td>
<td align="right">26</td>
<td align="right">50</td>
<td align="right">32</td>
<td align="right">112</td>
<td align="right">35</td>
</tr>
<tr class="odd">
<td align="left">no-Mr Peter Mahon.txt</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">8</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">no-Mr William Wells.txt</td>
<td align="right">61</td>
<td align="right">24</td>
<td align="right">73</td>
<td align="right">21</td>
<td align="right">128</td>
<td align="right">47</td>
</tr>
</tbody>
</table>
<p>The next section has a discussion of the ins and outs of hierarchical dictionaries and pattern matching. Alternatively you could just skip to the next major section to see how to make concordances.</p>
<div id="hierarchical-dictionaries" class="section level3">
<h3>Hierarchical dictionaries</h3>
<p>Because dictionaries are hierarchically structured (and have an extra column with word counts) simple row totals will almost never add up to the number of matches in the document. This matters when you want to treat the output as a contingency table, and gets more extreme the more nesting there is among the dictionary categories.</p>
<p>For example, assume that the <code>moral</code> category has within it two subcategories that distinguish religious and church-related language <code>church</code>, from general ethical considerations <code>ethical</code>. Further assume that all <code>moral</code> patterns are in one or other of these two subcategories. Then the output would contain two extra columns corresponding to the subcategories</p>
<pre><code> debate, ... debate_moral, debate_moral_church, debate_moral_ethical, ...
 201,    ... 14,           6,                   8, ...</code></pre>
<p>This structure is convenient if we want to be able to merge or separate the subcategories of <code>moral</code> in later analysis, but it does mean that the row of category counts now adds up to 215, not 201. On the other hand, we are guaranteed that 6 + 8 = 14.</p>
<p>But not even <em>this</em> will be true if there are patterns considered to be <code>moral</code> but neither <code>church</code> nor <code>ethical</code>, that is: patterns associated with <code>moral</code> but not with any of its subcategories. If these patterns were matched to 2 words in the first document then the output would look instead like</p>
<pre><code> debate, ... debate_moral, debate_moral_church, debate_moral_ethical, ...
 201, ...    16,           6,                   8, ...</code></pre>
<p>The upshot is: be careful what parts of the output you pass on to other tools.</p>
<p>If you are planning to analyse your data using statistical tools that assume a <em>contingency table</em> structure, then the duplicated counts from a hierarchical dictionary are probably not what you want. In these cases, pick a level of analysis and then remove the columns counting the sub and super categories with <code>dict_slice</code>.</p>
</div>
<div id="pattern-matching" class="section level3">
<h3>Pattern matching</h3>
<p>Dictionaries with patterns containing wildcards (basically the <code>*</code>) and patterns matching multiple words bring some subtle issues with word counting.</p>
<p>The first issue is when multiple patterns match the same word token. For example, the bara dictionary has no wildcards and therefore lists as matches in the <code>advocacy</code> category <code>objection</code>, <code>objectionable</code>, and <code>objections</code>. If we replaced the first two with <code>objection*</code> but left <code>objections</code> then we would double count every instance of <code>objections</code> in a document - once as an exact match to <code>objections</code> and then again as a match to <code>objection*</code>. With some care this kind of overlap can be avoided, but it is not always knowable in advance of seeing a document whether there are words that would match one or more patterns.</p>
<p>The issue is avoided by the tools by counting ‘token coverage’ not ‘token matches’. If, for the sake of the example, <code>objection*</code> and <code>objections</code> were the <em>only</em> two patterns in <code>advocacy</code> and they matched e.g. the 120th, 175th, and 210th word in some document, then we would record 3 tokens matched to <code>advocacy</code>, even though 6 word to pattern matches were actually made.</p>
<p>Counting coverage rather than matches also solves a similar problem generated by multiple word matches. If we counted matches using the patterns <code>united kingdom</code> and <code>united</code> then every instance of ‘united’ that preceded kingdom would be counted twice - once for matching the first half of <code>united kingdom</code> and once for matching <code>united</code>. Adding wildcards make this even harder to avoid the examining patterns. As before, if <code>united kingdom</code> matches the 25th and 26th word tokens in a document then <code>united</code> also matches the 25th, but only the number of tokens covered by patterns in the category are recorded - in this case 2.</p>
</div>
<div id="caveats-about-pattern-matching" class="section level3">
<h3>Caveats about pattern matching</h3>
<p>Counting token coverage rather than matches removes the risk of double counting within each category. It also removes the risk of double counting within a hierarchy of nested categories (technically the identities of the matched word tokens are ‘percolated’ up the category hierarchy from the lowest level). However, it does not prevent a double counting of a word by two categories at the same level.</p>
<p>For example, if the <code>church</code> and <code>ethical</code> subcategories of <code>moral</code> contained patterns that matched the same words, then each instance of those words in a document would increment both subcategories. This is not, in general, possible to prevent. (Sometimes it is not even problematic, depending on the purpose to which the dictionary is put). Note, however, that the counts associated with their supercategory <code>moral</code> would be correct and would not contain overcounts.</p>
</div>
<div id="old-school-pattern-matching" class="section level3">
<h3>Old school pattern matching</h3>
<p>If for some reason you liked the possibility of double-counting words, perhaps because you are replicating the analysis of someone who used a tool that did things that way, then you can set the <code>old.matching</code> parameter to TRUE.</p>
</div>
</div>
<div id="looking-at-words-and-categories-in-context" class="section level2">
<h2>Looking at words and categories in context</h2>
<p>If we want to see what sorts of things the dictionary is picking up in the documents we can arrange all the category matches in their local context. This is a form of concordance, or keyword in context (KWIC). Let’s have a look at the medical category.</p>
<pre class="sourceCode r"><code class="sourceCode r">debconc &lt;-<span class="st"> </span><span class="kw">jca_conc</span>(deb, <span class="dt">dictionary=</span>dict, <span class="dt">category=</span><span class="st">'medical'</span>)</code></pre>
<pre><code>## Folder is /var/folders/gl/ds8cxcyj07x0f553zt__04mm0000gn/T//RtmpLGRRKB/jca_concc6d2389919f2</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(debconc)</code></pre>
<pre><code>##                    Document
## 1 abs-Mr William Deedes.txt
## 2 abs-Mr William Deedes.txt
## 3 abs-Mr William Deedes.txt
## 4 abs-Mr William Deedes.txt
## 5 abs-Mr William Deedes.txt
## 6 abs-Mr William Deedes.txt
##                                                                                               Concordance
## 1                           layman, who is not a doctor or a lawyer, and cannot                          
## 2                    the change is the suffering mental and physical, inflicted on numberless            
## 3                   is the suffering, mental and physical, inflicted on numberless women who             
## 4                     places many members of the medical profession. It seems to me                      
## 5                      in a great many instances doctors today are confronted with a                     
## 6                  of discussion on this subject doctors have been treated as subsidiary</code></pre>
<p>The words we are matching are aligned in the middle of the second column and the document in which they occur is noted for each instance in the left column. Here the words we are looking at in context are: ‘doctor’, ‘physical’, ‘mental’, ‘medical’ and ‘doctors’.</p>
<p>If we are more interested in just one of these words, or in a completely new phrase we can skip the dictionary part and just hand in a pattern directly. Here we look at how each document uses a phrase</p>
<pre class="sourceCode r"><code class="sourceCode r">debconc2 &lt;-<span class="st"> </span><span class="kw">jca_conc</span>(deb, <span class="dt">pattern=</span><span class="st">'medical profession'</span>)</code></pre>
<pre><code>## Folder is /var/folders/gl/ds8cxcyj07x0f553zt__04mm0000gn/T//RtmpLGRRKB/jca_concc6d24fc01e17</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(debconc2)</code></pre>
<pre><code>##                    Document
## 1 abs-Mr William Deedes.txt
## 2 abs-Mr William Deedes.txt
## 3 abs-Mr William Deedes.txt
## 4 abs-Mr William Deedes.txt
## 5 abs-Mr William Deedes.txt
## 6 abs-Mr William Deedes.txt
##                                                                                      Concordance
## 1             places many members of the medical profession. It seems to me intolerable         
## 2         hon. Gentleman well knows, the medical profession comprises a great diversity of      
## 3                 by the attitude of the medical profession itself and by members of            
## 4                  to take away from the medical profession with one hand what we               
## 5           of uncertainty, to leave the medical profession in an area of doubt                 
## 6 administratively feasible, fair to the medical profession and it is to me</code></pre>
<p>Searching instead for the pattern <code>'medical *'</code> will show all pairs of words where the first is ‘medical’. This might be useful to see how many uses of ‘medical’ are not about the profession itself but rather about medical reasoning, medical procedures, and other staff. Very few, it turns out.</p>
<p>The asterisk is a wildcard that can be embedded in strings too, e.g. <code>'profess*'</code> will pick up all words starting with these letters.</p>
<p>If you just want to view the concordance, you can also ask to have it opened in a web browser by setting <code>open.browser</code> to TRUE. If you are actually more interested in sorting matches by pattern then you’ll need to set <code>prettyprint</code> to FALSE so that the output has three columns not two, where the second starts with the words the collocation line is centred on.</p>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
